{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transforms_func = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(416), \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomVerticalFlip(),   \n",
    "    transforms.RandomRotation(15),     \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), \n",
    "    transforms.Resize((416, 416)),      \n",
    "    transforms.ToTensor(),             \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Load the training dataset with augmentations\n",
    "train_datasets = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets1\\\\Seen Datasets/train',\n",
    "    transform=transforms_func\n",
    ")\n",
    "\n",
    "# Define the validation transformation (typically only resizing and normalization)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_datasets = datasets.ImageFolder(\n",
    "    'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets1\\\\Seen Datasets/val',\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data_dir = 'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets\\\\Seen Datasets'\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_datasets, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Depthwise Separable Convolution\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define MobileNet\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes=25):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            DepthwiseSeparableConv(32, 64, stride=1),\n",
    "            DepthwiseSeparableConv(64, 128, stride=2),\n",
    "            DepthwiseSeparableConv(128, 128, stride=1),\n",
    "            DepthwiseSeparableConv(128, 256, stride=2),\n",
    "            DepthwiseSeparableConv(256, 256, stride=1),\n",
    "            DepthwiseSeparableConv(256, 512, stride=2),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 1024, stride=2),\n",
    "            DepthwiseSeparableConv(1024, 1024, stride=1),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline / Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training function with gradient accumulation\n",
    "def train_mobilenet(num_classes, epochs, learning_rate, train_dataloader, val_dataloader, model_path, accumulation_steps=4):\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = MobileNet(num_classes=num_classes).cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_loader_tqdm = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader_tqdm):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_loader_tqdm.set_postfix(loss=running_loss/((i+1)/accumulation_steps), accuracy=100*correct/total)\n",
    "        \n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_dataloader, desc=f'Validation Epoch {epoch+1}/{epochs}'):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 704/704 [08:40<00:00,  1.35it/s, accuracy=12.3, loss=11.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.8467, Accuracy: 12.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/10: 100%|██████████| 235/235 [00:57<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.7609, Accuracy: 14.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 704/704 [08:29<00:00,  1.38it/s, accuracy=19.6, loss=10.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 2.5255, Accuracy: 19.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/10: 100%|██████████| 235/235 [00:56<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4946, Accuracy: 19.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 704/704 [08:21<00:00,  1.40it/s, accuracy=26, loss=9.3]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 2.3253, Accuracy: 25.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/10: 100%|██████████| 235/235 [00:55<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.3940, Accuracy: 25.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 704/704 [08:19<00:00,  1.41it/s, accuracy=30.5, loss=8.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 2.1742, Accuracy: 30.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/10: 100%|██████████| 235/235 [00:56<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2993, Accuracy: 26.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 704/704 [08:46<00:00,  1.34it/s, accuracy=35, loss=8.07]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 2.0173, Accuracy: 35.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/10: 100%|██████████| 235/235 [01:13<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.2543, Accuracy: 29.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 704/704 [09:23<00:00,  1.25it/s, accuracy=40.2, loss=7.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.8465, Accuracy: 40.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/10: 100%|██████████| 235/235 [01:11<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.5131, Accuracy: 27.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  30%|██▉       | 210/704 [02:48<06:36,  1.25it/s, accuracy=50.2, loss=6.12]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_mobilenet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobilenet_model(2).pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Accumulate gradients over 4 steps\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m, in \u001b[0;36mtrain_mobilenet\u001b[1;34m(num_classes, epochs, learning_rate, train_dataloader, val_dataloader, model_path, accumulation_steps)\u001b[0m\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 29\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_mobilenet(\n",
    "    num_classes=25,\n",
    "    epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    model_path='mobilenet_model.pth',\n",
    "    accumulation_steps=4  # Accumulate gradients over 4 steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RE-TRAINING  MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mobilenet(num_classes, epochs, learning_rate, train_dataloader, val_dataloader, model_path, accumulation_steps=4):\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = MobileNet(num_classes=25).cuda()\n",
    "    model.load_state_dict(torch.load('mobilenet_model(1).pth'))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_loader_tqdm = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader_tqdm):\n",
    "            inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            train_loader_tqdm.set_postfix(loss=running_loss/((i+1)/accumulation_steps), accuracy=100*correct/total)\n",
    "        \n",
    "        train_loss = running_loss / len(train_dataloader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%')\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_dataloader, desc=f'Validation Epoch {epoch+1}/{epochs}'):\n",
    "                inputs, labels = inputs.cuda(non_blocking=True), labels.cuda(non_blocking=True)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Data transforms\n",
    "    transforms_func = transforms.Compose([\n",
    "        transforms.Resize((416, 416)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),   \n",
    "        \n",
    "        # transforms.RandomRotation(15),\n",
    "        # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_transforms = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_datasets = datasets.ImageFolder(\n",
    "        'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets2\\\\Seen Datasets/train',\n",
    "        transform=transforms_func\n",
    "    )\n",
    "    val_datasets = datasets.ImageFolder(\n",
    "        'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets2\\\\Seen Datasets/val',\n",
    "        transform=val_transforms\n",
    "    )\n",
    "\n",
    "    batch_size = 32\n",
    "    train_dataloader = DataLoader(train_datasets, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_datasets, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 704/704 [18:01<00:00,  1.54s/it, accuracy=92.7, loss=0.913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2281, Accuracy: 92.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 1/10: 100%|██████████| 235/235 [02:57<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2475, Accuracy: 92.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 704/704 [15:00<00:00,  1.28s/it, accuracy=95.2, loss=0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.1585, Accuracy: 95.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 2/10: 100%|██████████| 235/235 [03:01<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2559, Accuracy: 92.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 704/704 [15:25<00:00,  1.31s/it, accuracy=95.3, loss=0.604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.1511, Accuracy: 95.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 3/10: 100%|██████████| 235/235 [03:25<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2290, Accuracy: 93.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 704/704 [16:10<00:00,  1.38s/it, accuracy=96.5, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.1122, Accuracy: 96.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 4/10: 100%|██████████| 235/235 [03:22<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2242, Accuracy: 93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 704/704 [15:41<00:00,  1.34s/it, accuracy=96.9, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.0983, Accuracy: 96.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 5/10: 100%|██████████| 235/235 [03:10<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2503, Accuracy: 92.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 704/704 [16:21<00:00,  1.39s/it, accuracy=97.5, loss=0.328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.0820, Accuracy: 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 6/10: 100%|██████████| 235/235 [03:14<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2067, Accuracy: 94.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 704/704 [15:50<00:00,  1.35s/it, accuracy=97, loss=0.37]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0925, Accuracy: 96.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 7/10: 100%|██████████| 235/235 [03:02<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2598, Accuracy: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 704/704 [15:34<00:00,  1.33s/it, accuracy=97, loss=0.371]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0928, Accuracy: 97.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 8/10: 100%|██████████| 235/235 [03:08<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2459, Accuracy: 93.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 704/704 [15:31<00:00,  1.32s/it, accuracy=97.5, loss=0.303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0757, Accuracy: 97.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 9/10: 100%|██████████| 235/235 [03:01<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2042, Accuracy: 93.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 704/704 [15:48<00:00,  1.35s/it, accuracy=97.7, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0709, Accuracy: 97.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation Epoch 10/10: 100%|██████████| 235/235 [03:11<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2135, Accuracy: 94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_mobilenet(\n",
    "        num_classes=25,\n",
    "        epochs=10,\n",
    "        learning_rate=0.001,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        model_path='mobilenet_model(2).pth',\n",
    "        accumulation_steps=4  # Accumulate gradients over 4 steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "USING MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets\\\\Seen Datasets\\\\val\\\\White-Breasted-Kingfisher'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m image_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msshak\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSeen Datasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSeen Datasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWhite-Breasted-Kingfisher\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Loop through every image in the folder\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_directory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Construct the full path to the image\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_directory, filename)\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Make sure it's a file (and optionally check if it's an image)\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\sshak\\\\Downloads\\\\Seen Datasets\\\\Seen Datasets\\\\val\\\\White-Breasted-Kingfisher'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Depthwise Separable Convolution\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define MobileNet\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes=25):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            DepthwiseSeparableConv(32, 64, stride=1),\n",
    "            DepthwiseSeparableConv(64, 128, stride=2),\n",
    "            DepthwiseSeparableConv(128, 128, stride=1),\n",
    "            DepthwiseSeparableConv(128, 256, stride=2),\n",
    "            DepthwiseSeparableConv(256, 256, stride=1),\n",
    "            DepthwiseSeparableConv(256, 512, stride=2),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 1024, stride=2),\n",
    "            DepthwiseSeparableConv(1024, 1024, stride=1),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define the same transformations as used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "model = MobileNet(num_classes=25).cuda()\n",
    "model.load_state_dict(torch.load('mobilenet_model.pth'))\n",
    "model.cuda()\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "def predict(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the image to GPU\n",
    "    image = image.cuda(non_blocking=True)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    return predicted.item()  # Return the predicted class index\n",
    "\n",
    "# Example usage\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "image_directory = r\"C:\\Users\\sshak\\Downloads\\Seen Datasets\\Seen Datasets\\val\\White-Breasted-Kingfisher\"\n",
    "\n",
    "# Loop through every image in the folder\n",
    "for filename in os.listdir(image_directory):\n",
    "    # Construct the full path to the image\n",
    "    image_path = os.path.join(image_directory, filename)\n",
    "    \n",
    "    # Make sure it's a file (and optionally check if it's an image)\n",
    "    if os.path.isfile(image_path):\n",
    "        predicted_class = predict(image_path)\n",
    "        print(f'Predicted class: {predicted_class}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "# Depthwise Separable Convolution\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define MobileNet\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes=25):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            DepthwiseSeparableConv(32, 64, stride=1),\n",
    "            DepthwiseSeparableConv(64, 128, stride=2),\n",
    "            DepthwiseSeparableConv(128, 128, stride=1),\n",
    "            DepthwiseSeparableConv(128, 256, stride=2),\n",
    "            DepthwiseSeparableConv(256, 256, stride=1),\n",
    "            DepthwiseSeparableConv(256, 512, stride=2),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "            DepthwiseSeparableConv(512, 512, stride=1),\n",
    "\n",
    "            DepthwiseSeparableConv(512, 1024, stride=2),\n",
    "            DepthwiseSeparableConv(1024, 1024, stride=1),\n",
    "\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define test transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),\n",
    "    # # transforms.RandomResizedCrop(416), \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomVerticalFlip(),   \n",
    "    transforms.RandomRotation(10),     \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load test data\n",
    "test_dataset = ImageFolder(root=r'C:\\Users\\sshak\\Downloads\\Seen Datasets2\\Seen Datasets\\val', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the saved model\n",
    "model = MobileNet(num_classes=25).cuda()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model = model.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Updated test function to include confusion matrix and classification report\n",
    "def test_model(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)  # Get probabilities\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())  # Collect probabilities\n",
    "            total_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    roc_auc = roc_auc_score(y_true, y_probs, multi_class='ovr')\n",
    "    logloss = log_loss(y_true, y_probs)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Test Precision: {precision:.2f}')\n",
    "    print(f'Test Recall: {recall:.2f}')\n",
    "    print(f'Test F1 Score: {f1:.2f}')\n",
    "    print(f'Test ROC-AUC: {roc_auc:.2f}')\n",
    "    print(f'Test Log Loss: {logloss:.2f}')\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report for each class\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "\n",
    "# Class names corresponding to your 25 classes\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "# Run the testing function\n",
    "test_model(model, test_loader, class_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
